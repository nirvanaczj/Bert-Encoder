<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="UTF-8">
  <title>Bert Universal Encoder</title>
  <link rel="stylesheet" href="./main.css">
  <link href="https://fonts.googleapis.com/css?family=Big+Shoulders+Display&display=swap" rel="stylesheet">
  <meta http-equiv="Access-Control-Allow-Origin" content="*" />  
</head>
<body>
    
<div class="full"> <div class="center"></div><br></div>
<div class="loading">
Trying my best to encode...
</div>

<div class="cursor"></div>
<h2 id='euclidean'></h2><br><br>
<h2 id='cosine'></h2>
    <div id="visualization">
    
    </div>
	<div class="container">
<form class="form">
<div class='left'>
<h1>Welcome to <span style="color:cornsilk"> Bert </span>Universal Encoder</h1>
<span style="font-size:1.5em">Built by ZiJia Chen.</span><br><br>
Tech Spec:<br>
1. Utilizing Bert NLP Pretrained model and specfically
<a href="https://bert-as-service.readthedocs.io/en/latest/" target="_blank" >Hanxiao's bert-as-service Public Repo </a><br>
2. Deployed through Google Cloud Platform's Virtual Computing Engine.<br>
3. Utilized Flask as server framework and deployed through RESTful API.
<br><br>
    What it can do:<br>
    Universally mapping two different/same length of sentences into an array of 1024 elements<br> and do <span style="color:cornsilk">Semantic Compare</span> through Euclidean Distance & Cosine Distance.
</div><br>
<!--
<div class='right'>
<span style="font-size:1.5em">Introduction to bert-as-service Universal Encoder</span><br>
<p>
    </p>BERT is a NLP model developed by Google for pre-training language representations. It leverages an enormous amount of plain text data publicly available on the web and is trained in an unsupervised manner. Pre-training a BERT model is a fairly expensive yet one-time procedure for each language. Fortunately, Google released several pre-trained models where you can download from here.<br><br>

Sentence Encoding/Embedding is a upstream task required in many NLP applications, e.g. sentiment analysis, text classification. The goal is to represent a variable length sentence into a fixed length vector, e.g. hello world to [0.1, 0.3, 0.9]. Each element of the vector should “encode” some semantics of the original sentence.
<br><br>
Finally, bert-as-service uses BERT as a sentence encoder and hosts it as a service via ZeroMQ, allowing you to map sentences into fixed-length representations.<br></div>

-->


           
    
    <br>

             <textarea
                  id="text1"
                  rows = "2"
                  cols = "40"
                  onkeyup="showsubmitBtn(this.value)"
                  placeholder = "try: I am hungry" ></textarea><br/><br/>
            <textarea 
                  id="text2"
                  rows = "2"
                  cols = "40"
                  placeholder = "try: I want to eat something" onkeyup="showsubmitBtn(this.value)"></textarea><br/><br/>
            <input type="submit" value="Test it out!"  onclick="myFunction()">

		</form>
        <div id="result"></div>
	</div>
    
    

<button class="refresh" onClick="window.location.reload();">
   Try again </button>
    <div class="boxNumber">
        The distance at this array element is (Mutiplied by 80):
        <span class="distance"></span>
   </div>
<div class='number'></div>
<script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>
<script  src="./script.js"></script>

</body>
</html>